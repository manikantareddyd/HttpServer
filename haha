Depending on where youâ€™ve lived youâ€™re probably using at least one of Â WhatsApp, WeChat, LINE, or Kakaotalk.Â At first glance, these apps lookÂ like communication tools. They allow you talk to your friends, family, coworkers and business partners. Sometimes all at once. But messenger apps are just the beginning of a much largerÂ trend. Pretty soon, youâ€™ll use such apps not to talk to your friends, but to talk to machines.Â Chat applications will become a new interface used to consume information and services. In fact, many companies have started to move into this direction. Weâ€™ll get toÂ that later, but bear with me for a little while.
Let me clarify what I mean by interface first. For the purpose of this post, an interfaceÂ is a layer of technology that facilitates the exchange of information and services between humans and machines. The perhaps most ubiquitous interface today is the web browser. Weâ€™ve invented several layers of complex technologies: HTTP, HTML, CSS, Javascript, and many others, to make the web browserÂ interface work well. Â The same is true for mobile apps, which shareÂ a lot of the same principles. Some people argue that a browsers and mobile apps are fundamentally different, but I disagree. There are subtle differences, but youâ€™re essentially looking at a screen and clicking or touching stuff. Theyâ€™re quiteÂ similar. In both cases, we use themÂ to communicate with other people (chat apps), find information (Google), and consume services (Amazon).
By design, all interfaces imposeÂ constraints on their users. Some constraints are good â€“ they forceÂ us to focus on the essential, making us more efficient. But Some are bottlenecks to our productivity, preventing us from doing what feels natural to us. Take search as an example. Humans are quite good at asking questions. Weâ€™ve beenÂ doing that for thousands of years. But can you have a conversation with Google to get the information you need? No, you canâ€™t. (Okay, except for a tiny fraction of very simple and commonly asked questions). Instead, weâ€™ve adjusted to the interface that Google is providingÂ us. Weâ€™re entering keywords that we think Google will be able to efficiently utilizeÂ to give us what we want. MostÂ of us are doing this unconsciously already because weâ€™ve been conditioned to do so. But if watch your mom, who didnâ€™t grow up with Google, youâ€™ll see that she has aÂ hard time wrapping herÂ head around what â€œgoodâ€ keywords are, and why sheÂ canâ€™t find what sheÂ needs. She also canâ€™t tell spam for non-spam. Keyword search doesnâ€™t come naturally to her.
Now, thereâ€™s an alternative interface that we use to communicate, get information and consumeÂ services almost every day: Natural Language. Natural Language is nothing more than the transmission of information, or meaning, through a medium such as sound or script. Thatâ€™s also why I wonâ€™t make a distinction between speech and text-based solutionÂ in this post. They both haveÂ their place, but they embody the same thing.Â LanguageÂ isÂ an interface that, right now, mostly facilitates communication between humans. But you could imagine using this same interface to facilitate communication between humansÂ and machines.Â Instead of putting keywords into Google youâ€™d ask a question, potentially have a quick conversation, and get a response. Instead of clicking through a dozen app screens youâ€™d just say what food you want to order, or tell your car where you want to go.
Just like other interfaces, the natural language interface has constraints. It isnâ€™t suited for everything. Obviously itâ€™s bad for visual tasks â€“ shopping clothes for example. It also doesnâ€™t seem soÂ great for discovery, like browsing items on Amazon without a clear goal. But you can certainly imagineÂ use cases where natural language excels. Asking questions to get information or conveying tasksÂ with a clear intention â€“ ordering a specific food item, cab, or giving directions for example. Natural Language places a low cognitive load on our brainsÂ because weâ€™re so used to P?Màÿit. Hence, it feels more natural and effortless than using an app or browser.
Of course, Facebook (M), Google (Now), Apple (Siri), Microsoft (Cortana) and Amazon (Echo) have been working on natural languages interface for a while now. Theyâ€™re calling it personal assistants (PAs). However, thereâ€™sÂ another group of companies who are attackingÂ the same problem from a different angle, but weâ€™ve been ignoring that part of their business. Â Messenger apps. These platformsÂ are uniquely positionedÂ to enable communicationÂ with machines. The leader of the pack is probably WeChat, which allows you to order everything from food to taxis from within the app, using a messaging as the interface. Slack is moving into the same direction by encouraging the creation ofÂ various bots.Â LINE also has a range of robotic accounts, ranging fromÂ translation services to eroticÂ entertainment.Â 
Why do I think these two groups of companies are working on the same problem? PAs follow what I would call a top-down approach. Theyâ€™re trying to solve a challenging problem with a long history in AI: Understanding your intentions and acting on them. They are trying to build general purpose software that is smart enough to also fulfill specific tasks.Â Itâ€™s a researchÂ area with lots of stuff left to figure out.Â Messenger apps follow a bottom-up approach.Â They are starting with simple bots (â€œHi, translate this sentence for meâ€), solving very specific problems,Â and are gradually moving towards more sophisticated AI.Â Over time, these two approaches will converge. 
When it comes to the adoption of natural language interfaces, messengers apps may actually have a leg up. Hereâ€™s why.Â Talking to Siri on a crowded train still feels awkward, even in SF. Itâ€™s also annoying because you have to open yet another app. However, many of us are spending our time in chat apps anyway, so it feels completely natural to justÂ add conversation with a bot. Ditto for Slack. The transition for consumers seems soÂ much smoother. As conversational interfaces penetrate our world, voice interfaces will startÂ feeling just as natural as taking selfies (and hopefully more than selfie sticks). But another reason for why messenger apps are well positioned is data. These companies have collected huge amounts of conversational data that can be used to train better Natural Language models. Facebook has that too, both with their messenger and with WhatsApp. Microsoft doesnâ€™t. Amazon doesnâ€™t. Apple may or may not, depending on how secure iMessage really is.
If youâ€™ve actually used any of the PAs you may be skeptical.Â Siri still barely understands what you want, and Facebook has put hordes of human workers behind M to get it to do anything useful.Â How willÂ these things ever replace all the complex tasks weâ€™reÂ doing apps and browsers? Thatâ€™sÂ another reason for why the bottom-up approach seemsÂ promising. It yields immediate benefits and practical applications.
But IÂ also believe that over the comingÂ years we will see rapid improvements in conversational interfaces. There are clear enabling technologies for this trend: Natural LanguageÂ Processing (NLP) and Deep Learning.Â Deep Learning techniques have led toÂ breakthroughs in Computer Vision, and they are now penetrating natural language research. Whether or not Deep Learning itself will lead to breakthroughs in NLP is hard to say, but one thing is clearly happening: Many smart people who didnâ€™tÂ previouslyÂ focus on NLP areÂ now seeing the potential and are starting working on NLP problems, and we can surely expect something to come out of this.
